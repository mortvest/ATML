\documentclass[a4paper]{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage[english]{babel}
\usepackage{float}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{xcolor}
%% \usepackage{subfigure}
\usepackage{pdfpages}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{stmaryrd}
\usepackage{a4wide}

\lstset{
  frame=tb,
  language=Python,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  formfeed=newpage,
  tabsize=4,
  comment=[l]{\#},
  breaklines=true,
  basicstyle=\small
}

\newcommand{\prob}[1]{\mathbb{P}\left(#1\right)}
\newcommand{\expect}[1]{\mathbb{E}\left(#1\right)}
\newcommand{\avg}[1]{\sum_{i=1}^{#1}X_i}
%% \newcommand{\dotp}[2]{\langle #1 + #2 \rangle}
%% \newcommand{\dotp}[2]{\ensuremath{\frac{#1}{#2}}}
\newcommand{\dotpr}[2]{\langle #1,\; #2 \rangle}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand*{\QEDA}{\hfill\ensuremath{\blacksquare}}%

\title{\vspace{-5cm}ATML Home Assignment 3}
\author{Dmitry Serykh (qwl888)}

\begin{document}
\maketitle
\section{Majority Vote}
\label{sec:1}
\subsection{}
\label{subsec:11}
Let hypotheses $h_1$, $h_2$ and $h_3$ be defined as on Table \ref{tab:1}. Then
$L(h)=\frac{1}{3}$ and $L(MV) = 0$ for all $h \in \mathcal{H}$  since the
prediction values match the true value for all $X \in \mathcal{X}$ and
$MV$ is a uniformly weighted majority vote.\\

\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|l|l|}
\hline
True value & $h_1$ & $h_2$ & $h_3$ & $MV_{\rho}$ \\ \hline
$h(X_1)$, $Y_1=-1$ & 1 & -1 & -1 & -1 \\ \hline
$h(X_2)$, $Y_2=-1$ & -1 & 1 & -1 & -1 \\ \hline
$h(X_3)$, $Y_3=-1$ & -1 & -1 & 1 & -1 \\ \hline
$L$ & $\frac{1}{3}$ & $\frac{1}{3}$ & $\frac{1}{3}$ & 0 \\ \hline
\end{tabular}
\caption{}
\label{tab:1}
\end{table}

\subsection{}
\label{subsec:22}
Let hypotheses $h_1$, $h_2$ and $h_3$ be defined as on Table \ref{tab:2}. Then
$L(h)=\frac{2}{3}$ and $L(MV) = 1$ for all $h \in \mathcal{H}$  since none of the
vote majority predictions match the true value for all $X \in \mathcal{X}$ and
$MV$ is a uniformly weighted majority vote.\\
Therefore it follow that $L(MV) > L(h)$ for all $h\in \mathcal{H}$.
\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|l|l|}
\hline
True value & $h_1$ & $h_2$ & $h_3$ & $MV_{\rho}$ \\ \hline
$h(X_1)$, $Y_1=1$ & 1 & -1 & -1 & -1 \\ \hline
$h(X_2)$, $Y_2=1$ & -1 & 1 & -1 & -1 \\ \hline
$h(X_3)$, $Y_3=1$ & -1 & -1 & 1 & -1 \\ \hline
$L$ & $\frac{2}{3}$ & $\frac{2}{3}$ & $\frac{2}{3}$ & 1 \\ \hline
\end{tabular}
\caption{}
\label{tab:2}
\end{table}

\subsection{}
\label{subsec:23}
\subsubsection*{a)}
Since $L(h_1) = L(h_2) = L(h_3) = p$ and errors of $h_1$, $h_2$ and $h_3$ are
independent, the probability for a hypothesis of getting a wrong prediction is
$p$. Then, the probability of $MV$ getting a wrong prediction equals the
probability of at least 2 hypotheses getting a wrong prediction:
\[
\binom{3}{3}p^3 + \binom{3}{2}p^3 = 4p^3
\]
Then:
\begin{align*}
  L(MV) = 4p^3
\end{align*}

\subsubsection*{b)}
I know the value of $L(MV)$ and that $L$ is the 0-1 loss, hence
$0 \leq p \leq  1$.
Therefore, I can solve the inequality for $p$:
\begin{align*}
  4p^3 &< p\\
  p^2 &< \frac{1}{4}\\
  0 < &p < \frac{1}{2}\\
\end{align*}
Thus, for $0 < p < \frac{1}{2}$ we have:
\[
L(MV) < p
\]

\section{Regularization by Relative Entropy and the Gibbs Distribution}
\label{sec:2}
I start by dropping the last constraint, hence the problem becomes:
\[
\begin{array}
  {ll}{\min _{\rho_{1}, \ldots, \rho_{m}}} &
  {\alpha \sum_{h=1}^{m} \rho_{h} L_{h}+\sum_{h=1}^{m} \rho_{h} \ln \frac{\rho_{h}}{\pi_{h}}} \\
  {\text {s.t.}} & {\sum_{h=1}^{m} \rho_{h}=1}
\end{array}
\]
Let $\rho$ be the vector of $\rho_1,...,\rho_m$, and
I define two functions:
\begin{align*}
g(\rho) &= \alpha \sum_{h=1}^{m} \rho_{h} L_{h}+\sum_{h=1}^{m} \rho_{h} \ln \frac{\rho_{h}}{\pi_{h}}\\
&= \alpha \sum_{h=1}^{m} \rho_{h} L_{h}+\sum_{h=1}^{m} \rho_{h} \ln \rho_{h} - \sum_{h=1}^{m}\rho_{h} \ln \pi_{h}\\
h(\rho) &= \sum_{h=1}^{m} \rho_{h} 
\end{align*}
and their gradients:
\begin{align*}
  \nabla g(\rho) &= \alpha L_{h} + \ln \rho_{h} + 1 - \ln \pi_{h}\\
  \nabla h(\rho) &= 1
\end{align*}
I then use the method of Lagrange multipliers to find the solution to the above
problem and solve the equality:  
\begin{align*}
  \nabla g(\rho) + \lambda h(\rho) &= 0\\
  \alpha L_{h} + \ln \rho_{h} + 1 - \ln \pi_{h} + \lambda \cdot 1 &= 0\\
  \ln \rho_{h} &= -\alpha L_{h} - 1 + \ln \pi_{h} - \lambda\\
  \rho_{h} &= e^{-\alpha L_{h} - 1 + \ln \pi_{h} - \lambda}\\
  \rho_{h} &= e^{\ln \pi_h} \cdot e^{-\alpha L_{h} - 1 + \ln \pi_{h} - \lambda}\\
  \rho_{h} &= \pi_{h}e^{-\alpha L_{h} - 1 - \lambda} 
\end{align*}
The value of $\rho_h$ is a product of two functions. $\pi_h \geq 0$ for all $h$
according to the definition of the ``prior distribution'' in the lecture notes.
The other factor is an exponential function with base $e>0$,
hence it can not be negative. Therefore, the value of $\rho_h \geq 0$ for all
$h$ and the solutions for the two problems from the assignment text are
identical. \\\\
I then find the solution, such that the constraint $\sum_{h=1}^m \rho_h = 1$ is
satisfied by solving for $\lambda$:
\begin{align*}
  \sum_{h=1}^m\pi_{h}e^{-\alpha L_{h} - 1 - \lambda} &= 1\\
  e^{ - 1 - \lambda}\sum_{h=1}^m\pi_{h}e^{-\alpha L_{h}} &= 1\\
  e^{ - 1 - \lambda} &= \frac{1}{\sum_{h=1}^m\pi_{h}e^{-\alpha L_{h}}}\\
  - 1 - \lambda &= \ln{1} - \ln\left(\frac{1}{\sum_{h=1}^m\pi_{h}e^{-\alpha L_{h}}} \right)\\
  \lambda &= \ln\left(\sum_{h=1}^m\pi_{h}e^{-\alpha L_{h}}\right) - 1
\end{align*}
and then substituting $\lambda$ with the result in the value of $\rho_h$, that I found earlier:
\begin{align*}
  \rho_{h} &= \pi_{h}e^{-\alpha L_{h} - 1 - \lambda} \\
  &= \pi_{h}e^{-\alpha L_{h} - 1 - (\ln\left(\sum_{h=1}^m\pi_{h}e^{-\alpha L_{h}}\right) - 1)} \\
  &= \pi_{h}e^{-\alpha L_{h} - \ln\left(\sum_{h=1}^m\pi_{h}e^{-\alpha L_{h}}\right)} \\
  &= \frac{\pi_{h}e^{-\alpha L_{h}}}{\sum_{h=1}^m\pi_{h}e^{-\alpha L_{h}}}
\end{align*}
That is exactly the solution that I was asked to find in the assignment text.

\section{Follow The Leader (FTL) algorithm for i.i.d. full information games}
\label{sec:3}
%% I will solve the problem for $K=2$, and I will work with rewards as in Section
I will work with rewards as in Section
5.3 in the lecture notes. I start by looking at the value of
the pseudo regret, which can be found on page 55 in the lecture notes:
\begin{align*}
  \bar{R}_T &= \sum_{a} \Delta(a) \mathbb{E}\left[N_{T}(a)\right]
  %% \\
  %% &= \Delta \mathbb{E}\left[N_{T}(a)\right]
\end{align*}
I know from the assignment text that:
\[
N_{T}(a)=\sum_{t=1}^{T} \mathbb{I}_{\left\{A_{t}=a\right\}}
\]
and
\[
\mathbb{E}\left[\mathbb{I}_{\left\{A_{t}=a\right\}}\right]
\leq \mathbb{P}\left\{\hat{\mu}_{t-1}(a) \geq \max _{a^{\prime}}
\hat{\mu}_{t-1}\left(a^{\prime}\right)\right\}
\leq \mathbb{P}\left\{\hat{\mu}_{t-1}(a) \geq \hat{\mu}_{t-1}\left(a^{*}\right)\right\}
\]
Then, by linearity of expectation:
\begin{align*}
  \bar{R}_T &\leq \sum_{a} \Delta(a) \sum_{t=1}^{T}\mathbb{P}\left\{\hat{\mu}_{t-1}(a) \geq \hat{\mu}_{t-1}\left(a^{*}\right)\right\}
\end{align*}
I will bound this probability by using the same method as in the lecture
notes (page 56):
\begin{align*}
  \mathbb{P}\left\{\hat{\mu}_{t-1}(a) \geq \hat{\mu}_{t-1}\left(a^{*}\right)\right\}
  &\leq \mathbb{P}\left(\hat{\mu}_{t-1}(a) \geq \mu(a)+\frac{1}{2}
  \Delta(a)\right)+\mathbb{P}\left(\hat{\mu}_{t-1}\left(a^{*}\right) \leq
  \mu^{*}-\frac{1}{2} \Delta(a)\right) \\
  &\leq e^{-2(t-1) \cdot (\frac{1}{2} \Delta(a))^2} + e^{-2(t-1) \cdot (-\frac{1}{2} \Delta(a))^2} \\
  &=2e^{-\frac{(t-1)\Delta(a)^2}{2}}
\end{align*}
The last inequality holds because of the Hoeffding's inequality, where
$\varepsilon = \pm \frac{1}{2}\Delta(a)$ and $n=t-1$.
I use the bound on the probability to bound the value of the pseudo regret:
\begin{align*}
  \bar{R}_T &\leq \sum_{a} \Delta(a)\sum_{t=1}^{T}2e^{-\frac{(t-1)\Delta(a)^2}{2}}\\
  &=\sum_{a} 2\Delta(a)\sum_{k=0}^{T}(e^{-\frac{\Delta(a)^2}{2}})^k \tag{$k=t-1$} \\
  &\leq \sum_{a} 2\Delta(a)\sum_{k=0}^{\infty}(e^{-\frac{\Delta(a)^2}{2}})^k 
  \tag{since $e > 0$}
\end{align*}
$e^{-\frac{\Delta(a)^2}{2}} \leq 1$ since the value of $\Delta(a) \geq 0$, which
can be concluded from the definition:
\[
\Delta(a)=\mu\left(a^{*}\right)-\mu(a) = \max _{a}[\mu(a)] - \mu(a) \geq 0
\]
Then, if we assure that $\Delta(a) > 0$, the
inequality becomes strict, and formula for the geometric series can be applied:
\[
\sum_{t=0}^{\infty} r^{t}=\frac{1}{1-r}\tag{for $r<1$}
\]
Hence, my final bound on the pseudo regret is:
\[
\bar{R}_T \leq \sum_{a:\; \Delta(a) > 0} \frac{2}{1- e^{-\frac{\Delta(a)^2}{2}}}\Delta(a) 
\]
\end{document}

%% \begin{figure}
%%   \centering
%%   \begin{subfigure}[b]{\textwidth}
%%     \centering
%%     \includegraphics[scale=0.8]{handin/plt51}
%%     \caption{Classification of the training set}
%%   \end{subfigure}
%%   \begin{subfigure}[b]{\textwidth}
%%     \centering
%%     \includegraphics[scale=0.8]{handin/plt52}
%%     \caption{Classification of the test set}
%%   \end{subfigure}
%%   \caption{Exercise 5: Logistic Regression Applied to the Datasets}
%%   \label{plt5}
%% \end{figure}

%% \begin{lstlisting}[caption="Calculation of g"]
%% def calc_g(Xs, y, w):
%%     N = np.shape(Xs)[0]
%%     # use matrix X of xs instead of for-loop = much faster
%%     X = np.c_[Xs, np.ones(N)]
%%     num = y.T * X
%%     denum = 1 + np.exp(y * (w @ X.T))
%%     M = num.T/denum
%%     # return mean of each row
%%     return (-1 * np.mean(M, axis=1))
%% \end{lstlisting}
