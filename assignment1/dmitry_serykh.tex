\documentclass[a4paper]{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage[english]{babel}
\usepackage{float}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{xcolor}
%% \usepackage{subfigure}
\usepackage{pdfpages}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{stmaryrd}
\usepackage{a4wide}

\lstset{
  frame=tb,
  language=Python,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  formfeed=newpage,
  tabsize=4,
  comment=[l]{\#},
  breaklines=true,
  morekeywords={models, lambda, forms}
}


\newcommand{\prob}[1]{\mathbb{P}\left(#1\right)}
\newcommand{\expect}[1]{\mathbb{E}\left(#1\right)}
\newcommand{\avg}[1]{\sum_{i=1}^{#1}X_i}
%% \newcommand{\dotp}[2]{\langle #1 + #2 \rangle}
%% \newcommand{\dotp}[2]{\ensuremath{\frac{#1}{#2}}}
\newcommand{\dotpr}[2]{\langle #1,\; #2 \rangle}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand*{\QEDA}{\hfill\ensuremath{\blacksquare}}%

\title{\vspace{-5cm} Assignment 3}
\author{Dmitry Serykh (qwl888)}

\begin{document}
\maketitle
%% \tableofcontents

%% \section*{Introduction}
%% \label{sec:intro}
%% This assignment was solved and written by myself, but the exercises were discussed
%% in a studygroup with following students:
%% \begin{itemize}
%% \item Frederik Thorøe
%% \item Thomas Kawiecki
%% \end{itemize}

\section{Grid World}
\label{sec:1}
\subsection{}
\label{subsec:11}
In order to calculate the value function $V^{rand}$ of the random policy, I
implement a version of the algorithm from the slide 31 in the reinforcement
learning lecture slides:
$$
  V(s) \leftarrow \sum_{a} \pi(s, a)
  \sum_{s^{\prime}} P_{s s^{\prime}}^{a}\left[R_{s s^{\prime}}^{a}+\gamma
    V(s^{\prime})\right]
  $$
An important observation is that all rewards and
transitions in this setup are deterministic, hence I can simplify the expression in the update
stage of the algorithm ($P_{s s^{\prime}}^{a} = 1$ for the transition state and
0 otherwise):
\begin{align*}
  &\sum_{a} \pi(s, a) \sum_{s^{\prime}} P_{s s^{\prime}}^{a}\left[R_{s s^{\prime}}^{a}+\gamma
    V(s^{\prime})\right] = 
  \sum_{a} \pi(s, a)
  \left[R_{s s^{\prime}}^{a} + V(s^{\prime})\right]
\end{align*}
where $s^{\prime}$ is the state after the transition. $s^{\prime}$ is found
by a simple lookup in the transitional mapping.\\
My implementation can be found in file \texttt{e1.py} in the \textbf{code.zip}
archive and the resulting value of $V^{rand}$ is:
\begin{verbatim}
[[-208.6 -206.1 -208.9]
 [-207.2 -191.8 -207.7]
 [-196.8 -173.5 -192.6]
 [-205.8  -88.7    0. ]]
\end{verbatim}

\subsection{}
\label{subsec:12}
My implementation can be found in file \texttt{e1.py} in the \textbf{code.zip}
archive and the resulting value of $V^{*}$ is:
\begin{verbatim}
[[-10.  -9. -10.]
 [ -9.  -3. -11.]
 [ -3.  -2.  -3.]
 [ -9.  -1.   0.]]
\end{verbatim}



\section{Numerical comparison of kl inequality with its relaxations and with Hoeffding’s inequality}
\subsection{}
\label{subsec:21}
The four bounds on $p$ are in a form ``with probability greater than $1 - \delta$'' and can
be explicitly written as:
\begin{enumerate}
\item $$p \leq \hat{p}_n+\sqrt{\frac{\ln \frac{1}{\delta}}{2 n}}$$
\item
  \begin{align*}
  p \leq \mathrm{kl}^{-1^{+}}\left(\hat{p}_{n}, z\right)
  \end{align*}
\item $$|p-\hat{p}_n| \leq \sqrt{\frac{\ln \frac{n+1}{\delta}}{2 n}}$$
\item $$ p \leq \hat{p}_n+\sqrt{\frac{2 \hat{p}_n \ln \frac{n+1}{\delta}}{n}}+\frac{2
  \ln \frac{n+1}{\delta}}{n}$$
\end{enumerate}

\section{Occam’s razor with kl inequality}
I start by looking at inequality (2.11) from the lecture notes, where with
probability greater than $1-\delta$:
$$
\mathrm{kl}(\hat{p} \| p) \leq \frac{\ln \frac{n+1}{\delta}}{n}
$$
An alternative way of looking at the theorem is:
\begin{equation}\label{kl1}
\mathbb{P}(
\mathrm{kl}(\hat{p} \| p) \geq \frac{\ln \frac{n+1}{\delta}}{n}
) \leq \delta \tag{1}
\end{equation}
I want to prove that for $\delta \in(0,1)$, with probability greater than
$1-\delta$ for all $h \in \mathcal{H}$:
$$
\mathrm{kl}(\hat{L}(h, S) \| L(h)) \leq \frac{\ln \frac{n+1}{\pi(h) \delta}}{n}
$$
But instead, I will prove the equivalent statement by following a method similar
to the proof of the Occam's Razor bound with the Hoeffding's inequality in the
lecture slides:
$$
  \mathbb{P}(\exists h \in \mathcal{H} :
  \mathrm{kl}(\hat{L}(h) \| L(h)) \geq \frac{\ln \frac{n+1}{\pi(h)\delta}}{n})
  \leq \delta
$$
I prove it by looking at the left-hand side of the inequality:
\begin{align*}
  \mathbb{P}(\exists h \in \mathcal{H} :
  \mathrm{kl}(\hat{L}(h) \| L(h)) \geq \frac{\ln \frac{n+1}{\pi(h)\delta}}{n})
  &\leq
  \sum_{h \in \mathcal{H}}
  \mathbb{P} (\mathrm{kl}(\hat{L}(h) \| L(h)) \geq \frac{\ln \frac{n+1}{\pi(h)\delta}}{n})\\
  &\leq
  \sum_{h \in \mathcal{H}}\pi(h)\delta \\
  &\leq
  \delta
\end{align*}
The first inequality holds because of the union bound. The second 
holds because of (\ref{kl1}) and the fact that $\pi(h)$ is 
independent from $S$. The last inequality holds because 
$\sum_{h \in \mathcal{H}} \pi(h) \leq 1$. \QEDA

\section{Refined Pinsker’s Lower Bound}
I need to prove that if $\mathrm{kl}(p \| q) \leq \varepsilon$ then
$q \geq p-\sqrt{2 p \varepsilon}$. 

\begin{align*}
  \frac{(p-q)^{2}}{2 \max \{p, q\}}+\frac{(p-q)^{2}}{2 \max \{(1-p),(1-q)\}}
  \leq \varepsilon
\end{align*}

$$
q \leq p+\sqrt{2 p \varepsilon}+2 \varepsilon
$$
\section{The Importance of Independence}
Let us define Bernoulli random variables $X_1, X_2, ..., X_n$ with bias $0.5$.
Let the value of $X_i = X_0$ for $i>1$. Then the value of
$\sum_{i=1}^{n} X_{i}$ would always be either 0 or 1 and
$\mu = \mathbb{E}\left[X_{i}\right] = \frac{1}{2} \cdot 0 + \frac{1}{2} \cdot 1 = \frac{1}{2}$.\\
Hence, the average would not converge to $\mu$ and we have:
$$
\mathbb{P}\left\{\left|\mu-\frac{1}{n} \sum_{i=1}^{n} X_{i}\right| \geq \frac{1}{2}\right\}=1
$$

\end{document}

%% \begin{figure}
%%   \centering
%%   \begin{subfigure}[b]{\textwidth}
%%     \centering
%%     \includegraphics[scale=0.8]{handin/plt51}
%%     \caption{Classification of the training set}
%%   \end{subfigure}
%%   \begin{subfigure}[b]{\textwidth}
%%     \centering
%%     \includegraphics[scale=0.8]{handin/plt52}
%%     \caption{Classification of the test set}
%%   \end{subfigure}
%%   \caption{Exercise 5: Logistic Regression Applied to the Datasets}
%%   \label{plt5}
%% \end{figure}

%% \begin{lstlisting}[caption="Calculation of g"]
%% def calc_g(Xs, y, w):
%%     N = np.shape(Xs)[0]
%%     # use matrix X of xs instead of for-loop = much faster
%%     X = np.c_[Xs, np.ones(N)]
%%     num = y.T * X
%%     denum = 1 + np.exp(y * (w @ X.T))
%%     M = num.T/denum
%%     # return mean of each row
%%     return (-1 * np.mean(M, axis=1))
%% \end{lstlisting}
